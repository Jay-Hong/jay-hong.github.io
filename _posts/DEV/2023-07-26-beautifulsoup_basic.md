---
title:  ğŸœ BeautifulSoup Basic ğŸŒ±
categories: Crawling
tag: [ğŸœ BeautifulSoup, ğŸŒ± basics]
toc: true
excerpt: false
---


## BeautifulSoup Basic


```python
import requests
from bs4 import BeautifulSoup
res = requests.get('http://v.media.daum.net/v/20170615203441266')
soup = BeautifulSoup(res.content, 'html.parser')
mydata = soup.find('title')
print(mydata.get_text())
```

    ì”ê¸ˆëŒ€ì¶œì—ë„ DTI ê·œì œ ì ìš© ê²€í† 


data = soup.find('p', class_='cssstyle)
data = soup.find('p', 'cssstyle')
data = soup.find('p', attrs = {'align' : 'center'})
data = soup.find(id='body')


```python
from bs4 import BeautifulSoup
html = """
<html>
    <body>
        <h1 id'title>[1]í¬ë¡¤ë§ì´ë‘?</h1>
        <p class='cssstyle'>ì›¹í˜ì´ì§€ì—ì„œ í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒ</p>
        <p id='body' align='center'>íŒŒì´ì¬ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ì–‘í•œ ì›¹í¬ë¡¤ë§ ê¸°ìˆ  ë°œë‹¬</p>
    <body>
</html>
"""
soup = BeautifulSoup(html, 'html.parser')
# íƒœê·¸ë¡œ ê²€ìƒ‰ ë°©ë²•
data = soup.find('p', attrs={'id':'body', 'align':'center'})
#print(data)
print(data.string)
#print(data.get_text())
```

    íŒŒì´ì¬ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ì–‘í•œ ì›¹í¬ë¡¤ë§ ê¸°ìˆ  ë°œë‹¬



```python
data = soup.find_all('p')
for item in data:
    print(item.string)
```

    ì›¹í˜ì´ì§€ì—ì„œ í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒ
    íŒŒì´ì¬ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ì–‘í•œ ì›¹í¬ë¡¤ë§ ê¸°ìˆ  ë°œë‹¬



```python
import requests
from bs4 import BeautifulSoup

res = requests.get('http://v.media.daum.net/v/20170615203441266')
soup = BeautifulSoup(res.content, 'html.parser')

mydata = soup.find('div', 'layer_body')

detail = mydata.get_text()
detail
```




    '\nê¸ˆìœµë‹¹êµ­ì´ ê¸‰ì¦í•˜ëŠ” ê°€ê³„ë¶€ì±„ ì¦ê°€ì„¸ë¥¼ ë§‰ê¸° ìœ„í•´ ì•„íŒŒíŠ¸ ì”ê¸ˆëŒ€ì¶œì—ë„ ì†Œë“ì„ ë”°ì ¸ ëŒ€ì¶œí•œë„ë¥¼ ì •í•˜ëŠ” ì´ë¶€ì±„ìƒí™˜ë¹„ìœ¨(DTI)ì„ ì ìš©í•˜ëŠ” ë°©ì•ˆì„ ìœ ë ¥í•˜ê²Œ ê²€í† í•˜ê³  ìˆë‹¤.\nì§€ê¸ˆì€ ì§‘ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¶œí•œë„ë¥¼ ë§¤ê¸°ëŠ” ì£¼íƒë‹´ë³´ì¸ì •ë¹„ìœ¨(LTV) ê·œì œë§Œ ì ìš©ë¼ ì†Œë“ì´ ì—†ì–´ë„ ì§‘ê°’ì˜ 70%ë¥¼ ë¹Œë ¤ ì”ê¸ˆì„ ì¹˜ë¥´ëŠ” ê²Œ ê°€ëŠ¥í•˜ë‹¤.\nì•ìœ¼ë¡œ ì”ê¸ˆëŒ€ì¶œì— DTIê°€ ì ìš©ë˜ë©´ ì†Œë“ì´ ì—†ëŠ” ì‚¬ëŒì€ ì§‘ê°’ì˜ 70% ëŒ€ì¶œ ë°›ëŠ” ê²Œ ì–´ë ¤ì›Œì§„ë‹¤.\n'




```python
import requests
from bs4 import BeautifulSoup

res = requests.get('https://davelee-fun.github.io/blog/crawl_test')
soup = BeautifulSoup(res.content, 'html.parser')

titles = soup.find_all('li', 'course')
for title in titles:
    print(title.get_text())
```

    (ì™•ì´ˆë³´) - í´ë˜ìŠ¤ ì†Œê°œ
    (ì™•ì´ˆë³´) - ë¸”ë¡œê·¸ ê°œë°œ í•„ìš”í•œ ì¤€ë¹„ë¬¼ ì¤€ë¹„í•˜ê¸°
    (ì™•ì´ˆë³´) - Github pages ì„¤ì •í•´ì„œ ë¸”ë¡œê·¸ ì²« í˜ì´ì§€ ë§Œë“¤ì–´ë³´ê¸°
    (ì™•ì´ˆë³´) - ì´ˆê°„ë‹¨ í˜ì´ì§€ ë§Œë“¤ì–´ë³´ê¸°
    (ì™•ì´ˆë³´) - ì´ì˜ê²Œ í…Œë§ˆ ì ìš©í•´ë³´ê¸°
    (ì™•ì´ˆë³´) - ë§ˆí¬ë‹¤ìš´ ê¸°ì´ˆ ì´í•´í•˜ê³ , ì‹¤ì œ ë‚˜ë§Œì˜ ë¸”ë¡œê·¸ í˜ì´ì§€ ë§Œë“¤ê¸°
    (ì™•ì´ˆë³´) - ë‹¤ì–‘í•œ ë§ˆí¬ë‹¤ìš´ ê¸°ë²• ìµí˜€ë³´ë©°, ë‚˜ë§Œì˜ ë¸”ë¡œê·¸ í˜ì´ì§€ ê¾¸ë©°ë³´ê¸°
    (ì´ˆê¸‰) - ê°•ì‚¬ê°€ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ìë™ í”„ë¡œê·¸ë¨ ì†Œê°œ [2]
    (ì´ˆê¸‰) - í•„ìš”í•œ í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ì‹œì—° [5]
    (ì´ˆê¸‰) - ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë§Œë“¤ê¸° [9]
    (ì´ˆê¸‰) - Â Â Â Â ì—‘ì…€ íŒŒì¼ ì´ì˜ê²Œ! ì´ì˜ê²Œ! [8]
    (ì´ˆê¸‰) - Â Â Â Â ë‚˜ëŒ€ì‹  ì£¼ê¸°ì ìœ¼ë¡œ íŒŒì´ì¬ í”„ë¡œê·¸ë¨ ì‹¤í–‰í•˜ê¸° [7]
    (ì´ˆê¸‰) - íŒŒì´ì¬ìœ¼ë¡œ ìŠ¬ë™(slack) ë©”ì‹ ì €ì— ê¸€ì“°ê¸° [40]
    (ì´ˆê¸‰) - ì›¹ì‚¬ì´íŠ¸ ë³€ê²½ì‚¬í•­ ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í•´ì„œ, ë©”ì‹ ì €ë¡œ ì•ŒëŒì£¼ê¸° [12]
    (ì´ˆê¸‰) - ë„¤ì´ë²„ API ì‚¬ìš©í•´ì„œ, ë¸”ë¡œê·¸ì— ê¸€ì“°ê¸° [42]
    (ì¤‘ê¸‰) - ìë™ìœ¼ë¡œ ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ API ë¡œ ê°€ì ¸ì˜¨ ìƒí’ˆ ì •ë³´, ë„¤ì´ë²„ ë¸”ë¡œê·¸/íŠ¸ìœ„í„°ì— í™ë³´í•˜ê¸° [412]



```python
import requests
from bs4 import BeautifulSoup

res = requests.get('https://davelee-fun.github.io/blog/crawl_test')
soup = BeautifulSoup(res.content, 'html.parser')

section = soup.find('ul', id="dev_course_list")
titles = section.find_all('li', 'course')

for title in titles:
    print(title.get_text())
```

    (ì´ˆê¸‰) - ê°•ì‚¬ê°€ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ìë™ í”„ë¡œê·¸ë¨ ì†Œê°œ [2]
    (ì´ˆê¸‰) - í•„ìš”í•œ í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ì‹œì—° [5]
    (ì´ˆê¸‰) - ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë§Œë“¤ê¸° [9]
    (ì´ˆê¸‰) - Â Â Â Â ì—‘ì…€ íŒŒì¼ ì´ì˜ê²Œ! ì´ì˜ê²Œ! [8]
    (ì´ˆê¸‰) - Â Â Â Â ë‚˜ëŒ€ì‹  ì£¼ê¸°ì ìœ¼ë¡œ íŒŒì´ì¬ í”„ë¡œê·¸ë¨ ì‹¤í–‰í•˜ê¸° [7]
    (ì´ˆê¸‰) - íŒŒì´ì¬ìœ¼ë¡œ ìŠ¬ë™(slack) ë©”ì‹ ì €ì— ê¸€ì“°ê¸° [40]
    (ì´ˆê¸‰) - ì›¹ì‚¬ì´íŠ¸ ë³€ê²½ì‚¬í•­ ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í•´ì„œ, ë©”ì‹ ì €ë¡œ ì•ŒëŒì£¼ê¸° [12]
    (ì´ˆê¸‰) - ë„¤ì´ë²„ API ì‚¬ìš©í•´ì„œ, ë¸”ë¡œê·¸ì— ê¸€ì“°ê¸° [42]
    (ì¤‘ê¸‰) - ìë™ìœ¼ë¡œ ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ API ë¡œ ê°€ì ¸ì˜¨ ìƒí’ˆ ì •ë³´, ë„¤ì´ë²„ ë¸”ë¡œê·¸/íŠ¸ìœ„í„°ì— í™ë³´í•˜ê¸° [412]



```python
import requests
from bs4 import BeautifulSoup

res = requests.get('https://davelee-fun.github.io/blog/crawl_test')
soup = BeautifulSoup(res.content, 'html.parser')

section = soup.find('ul', id="dev_course_list")
titles = section.find_all('li', 'course')

for title in titles:
    print(title.get_text().split('[')[0].split('-')[1].strip())
```

    ê°•ì‚¬ê°€ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ìë™ í”„ë¡œê·¸ë¨ ì†Œê°œ
    í•„ìš”í•œ í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ì‹œì—°
    ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë§Œë“¤ê¸°
    ì—‘ì…€ íŒŒì¼ ì´ì˜ê²Œ! ì´ì˜ê²Œ!
    ë‚˜ëŒ€ì‹  ì£¼ê¸°ì ìœ¼ë¡œ íŒŒì´ì¬ í”„ë¡œê·¸ë¨ ì‹¤í–‰í•˜ê¸°
    íŒŒì´ì¬ìœ¼ë¡œ ìŠ¬ë™(slack) ë©”ì‹ ì €ì— ê¸€ì“°ê¸°
    ì›¹ì‚¬ì´íŠ¸ ë³€ê²½ì‚¬í•­ ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í•´ì„œ, ë©”ì‹ ì €ë¡œ ì•ŒëŒì£¼ê¸°
    ë„¤ì´ë²„ API ì‚¬ìš©í•´ì„œ, ë¸”ë¡œê·¸ì— ê¸€ì“°ê¸°
    ìë™ìœ¼ë¡œ ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ API ë¡œ ê°€ì ¸ì˜¨ ìƒí’ˆ ì •ë³´, ë„¤ì´ë²„ ë¸”ë¡œê·¸/íŠ¸ìœ„í„°ì— í™ë³´í•˜ê¸°



```python
import requests
from bs4 import BeautifulSoup

res = requests.get('https://davelee-fun.github.io/blog/crawl_test')
soup = BeautifulSoup(res.content, 'html.parser')

section = soup.find('ul', id="dev_course_list")
titles = section.find_all('li', 'course')

for index, title in enumerate(titles):
    print(str(index + 1) + '.', title.get_text().split('[')[0].split('-')[1].strip())
```

    1. ê°•ì‚¬ê°€ ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ìë™ í”„ë¡œê·¸ë¨ ì†Œê°œ
    2. í•„ìš”í•œ í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ì‹œì—°
    3. ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë§Œë“¤ê¸°
    4. ì—‘ì…€ íŒŒì¼ ì´ì˜ê²Œ! ì´ì˜ê²Œ!
    5. ë‚˜ëŒ€ì‹  ì£¼ê¸°ì ìœ¼ë¡œ íŒŒì´ì¬ í”„ë¡œê·¸ë¨ ì‹¤í–‰í•˜ê¸°
    6. íŒŒì´ì¬ìœ¼ë¡œ ìŠ¬ë™(slack) ë©”ì‹ ì €ì— ê¸€ì“°ê¸°
    7. ì›¹ì‚¬ì´íŠ¸ ë³€ê²½ì‚¬í•­ ì£¼ê¸°ì ìœ¼ë¡œ ì²´í¬í•´ì„œ, ë©”ì‹ ì €ë¡œ ì•ŒëŒì£¼ê¸°
    8. ë„¤ì´ë²„ API ì‚¬ìš©í•´ì„œ, ë¸”ë¡œê·¸ì— ê¸€ì“°ê¸°
    9. ìë™ìœ¼ë¡œ ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ API ë¡œ ê°€ì ¸ì˜¨ ìƒí’ˆ ì •ë³´, ë„¤ì´ë²„ ë¸”ë¡œê·¸/íŠ¸ìœ„í„°ì— í™ë³´í•˜ê¸°


## selector


```python
import requests
from bs4 import BeautifulSoup

res = requests.get('https://davelee-fun.github.io/blog/crawl_test')
soup = BeautifulSoup(res.content, 'html.parser')

items = soup.select('h3')
for item in items:
    print(item.get_text())
```

    ë‚˜ë§Œì˜ ì—£ì§€ìˆëŠ” ë¸”ë¡œê·¸ ì‚¬ì´íŠ¸ ë§Œë“¤ê¸°
    ë‹¹ì‹ ì˜ ì»¤ë¦¬ì–´ì— íŒŒì´ì¬ì„ ì…íˆì„¸ìš”! ìì‹ ë§Œì˜ ìë™ í”„ë¡œê·¸ë¨ê¹Œì§€ ê°€ì ¸ê°€ëŠ” íŠ¹ë³„í•œ ê°•ì˜



```python
import openpyxl

def write_excel_template(filename, sheetname, listdata):
    excel_file = openpyxl.Workbook()
    excel_sheet = excel_file.active
    excel_sheet.column_demensions['A'].width = 100
    
    if sheetname != '':
        excel_sheet.title = sheetname
        
    for item in listdata:
        excel_sheet.apend(item)
    excel_file.save(filename)
    excel_file.close()
```
